# Introduction

**LangChain** is a framework for developing applications powered by language models. It enables applications that:
- **Are context-aware**: connect a language model to sources of context (prompt instructions, few shot examples, content to ground its response in, etc.)
- **Reason**: rely on a language model to reason (about how to answer based on provided context, what actions to take, etc.)

This library offers integration with the following Generative AI servers:
* [AWS Bedrock](https://us-west-2.console.aws.amazon.com/bedrock/home)
* [Azure OpenAI](https://azure.microsoft.com/en-us/products/ai-services/openai-service)
* [Google AI Studio](https://aistudio.google.com/)
* [ollama](https://ollama.com/) 
* [Oracle Cloud Infrastructure AI](https://www.oracle.com/artificial-intelligence/ai-services/)

This library extends LangChain by providing facilities to define configurations, templates for execution of LLMs.

## Get started
[Hereâ€™s](installation.md) how to install library, set up your environment, and start building.

<div style="text-align: center;">
  <hr/>
  <img src="../../img/rqle_ai_logo_alt.jpeg" alt="RQle.AI" width="60"/>
  &nbsp; RQle.AI - 2024
</div>
